{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad6e8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch \n",
    "import scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b4aa410",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Person_ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Depression_Score</th>\n",
       "      <th>Anxiety_Score</th>\n",
       "      <th>Stress_Level</th>\n",
       "      <th>Previous_Mental_Health_Diagnosis</th>\n",
       "      <th>Substance_Use</th>\n",
       "      <th>Social_Support_Score</th>\n",
       "      <th>Sleep_Quality</th>\n",
       "      <th>Academic_or_Work_Stress</th>\n",
       "      <th>Recent_Life_Event</th>\n",
       "      <th>Physical_Health_Issues</th>\n",
       "      <th>Self_Esteem_Score</th>\n",
       "      <th>Help_Seeking_Behavior</th>\n",
       "      <th>Suicide_Risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P00001</td>\n",
       "      <td>56</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>6</td>\n",
       "      <td>Average</td>\n",
       "      <td>High</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>7</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P00002</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>4</td>\n",
       "      <td>Good</td>\n",
       "      <td>Medium</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P00003</td>\n",
       "      <td>32</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>Good</td>\n",
       "      <td>Medium</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>5</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P00004</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>7</td>\n",
       "      <td>Average</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>6</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P00005</td>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>Average</td>\n",
       "      <td>Low</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Person_ID  Age  Depression_Score  Anxiety_Score  Stress_Level  \\\n",
       "0    P00001   56                 3              9             3   \n",
       "1    P00002   46                 0              1             6   \n",
       "2    P00003   32                 7              2             8   \n",
       "3    P00004   25                 1              4             0   \n",
       "4    P00005   38                 2              2             5   \n",
       "\n",
       "  Previous_Mental_Health_Diagnosis Substance_Use  Social_Support_Score  \\\n",
       "0                              Yes            No                     6   \n",
       "1                              Yes            No                     4   \n",
       "2                              Yes            No                     1   \n",
       "3                               No            No                     7   \n",
       "4                              Yes            No                     2   \n",
       "\n",
       "  Sleep_Quality Academic_or_Work_Stress Recent_Life_Event  \\\n",
       "0       Average                    High               Yes   \n",
       "1          Good                  Medium                No   \n",
       "2          Good                  Medium                No   \n",
       "3       Average                  Medium               Yes   \n",
       "4       Average                     Low                No   \n",
       "\n",
       "  Physical_Health_Issues  Self_Esteem_Score Help_Seeking_Behavior Suicide_Risk  \n",
       "0                     No                  7                    No           No  \n",
       "1                    Yes                  3                   Yes           No  \n",
       "2                     No                  5                   Yes          Yes  \n",
       "3                     No                  6                   Yes           No  \n",
       "4                    Yes                  3                   Yes           No  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv('suicide_risk_synthetic_10k.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d52400cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Person_ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Depression_Score</th>\n",
       "      <th>Anxiety_Score</th>\n",
       "      <th>Stress_Level</th>\n",
       "      <th>Previous_Mental_Health_Diagnosis</th>\n",
       "      <th>Substance_Use</th>\n",
       "      <th>Social_Support_Score</th>\n",
       "      <th>Sleep_Quality</th>\n",
       "      <th>Academic_or_Work_Stress</th>\n",
       "      <th>Recent_Life_Event</th>\n",
       "      <th>Physical_Health_Issues</th>\n",
       "      <th>Self_Esteem_Score</th>\n",
       "      <th>Help_Seeking_Behavior</th>\n",
       "      <th>Suicide_Risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>56</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>6</td>\n",
       "      <td>Average</td>\n",
       "      <td>High</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>7</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>4</td>\n",
       "      <td>Good</td>\n",
       "      <td>Medium</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>Good</td>\n",
       "      <td>Medium</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>5</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>7</td>\n",
       "      <td>Average</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>6</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>Average</td>\n",
       "      <td>Low</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Person_ID  Age  Depression_Score  Anxiety_Score  Stress_Level  \\\n",
       "0          1   56                 3              9             3   \n",
       "1          2   46                 0              1             6   \n",
       "2          3   32                 7              2             8   \n",
       "3          4   25                 1              4             0   \n",
       "4          5   38                 2              2             5   \n",
       "\n",
       "  Previous_Mental_Health_Diagnosis Substance_Use  Social_Support_Score  \\\n",
       "0                              Yes            No                     6   \n",
       "1                              Yes            No                     4   \n",
       "2                              Yes            No                     1   \n",
       "3                               No            No                     7   \n",
       "4                              Yes            No                     2   \n",
       "\n",
       "  Sleep_Quality Academic_or_Work_Stress Recent_Life_Event  \\\n",
       "0       Average                    High               Yes   \n",
       "1          Good                  Medium                No   \n",
       "2          Good                  Medium                No   \n",
       "3       Average                  Medium               Yes   \n",
       "4       Average                     Low                No   \n",
       "\n",
       "  Physical_Health_Issues  Self_Esteem_Score Help_Seeking_Behavior Suicide_Risk  \n",
       "0                     No                  7                    No           No  \n",
       "1                    Yes                  3                   Yes           No  \n",
       "2                     No                  5                   Yes          Yes  \n",
       "3                     No                  6                   Yes           No  \n",
       "4                    Yes                  3                   Yes           No  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data.columns[0]] = data[data.columns[0]].apply(lambda x: int(x[1:]))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56b4470a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Person_ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Depression_Score</th>\n",
       "      <th>Anxiety_Score</th>\n",
       "      <th>Stress_Level</th>\n",
       "      <th>Previous_Mental_Health_Diagnosis</th>\n",
       "      <th>Substance_Use</th>\n",
       "      <th>Social_Support_Score</th>\n",
       "      <th>Sleep_Quality</th>\n",
       "      <th>Academic_or_Work_Stress</th>\n",
       "      <th>Recent_Life_Event</th>\n",
       "      <th>Physical_Health_Issues</th>\n",
       "      <th>Self_Esteem_Score</th>\n",
       "      <th>Help_Seeking_Behavior</th>\n",
       "      <th>Suicide_Risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>56</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Person_ID  Age  Depression_Score  Anxiety_Score  Stress_Level  \\\n",
       "0          1   56                 3              9             3   \n",
       "1          2   46                 0              1             6   \n",
       "2          3   32                 7              2             8   \n",
       "3          4   25                 1              4             0   \n",
       "4          5   38                 2              2             5   \n",
       "\n",
       "   Previous_Mental_Health_Diagnosis  Substance_Use  Social_Support_Score  \\\n",
       "0                                 1              0                     6   \n",
       "1                                 1              0                     4   \n",
       "2                                 1              0                     1   \n",
       "3                                 0              0                     7   \n",
       "4                                 1              0                     2   \n",
       "\n",
       "   Sleep_Quality  Academic_or_Work_Stress  Recent_Life_Event  \\\n",
       "0              1                        2                  1   \n",
       "1              2                        1                  0   \n",
       "2              2                        1                  0   \n",
       "3              1                        1                  1   \n",
       "4              1                        0                  0   \n",
       "\n",
       "   Physical_Health_Issues  Self_Esteem_Score  Help_Seeking_Behavior  \\\n",
       "0                       0                  7                      0   \n",
       "1                       1                  3                      1   \n",
       "2                       0                  5                      1   \n",
       "3                       0                  6                      1   \n",
       "4                       1                  3                      1   \n",
       "\n",
       "   Suicide_Risk  \n",
       "0             0  \n",
       "1             0  \n",
       "2             1  \n",
       "3             0  \n",
       "4             0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode ordinal categorical variables\n",
    "sleep_mapping = {'Poor': 0, 'Average': 1, 'Good': 2}\n",
    "stress_mapping = {'Low': 0, 'Medium': 1, 'High': 2}\n",
    "yes_no_dict = {\"Yes\": 1, \"No\":0}\n",
    "\n",
    "data['Sleep_Quality'] = data['Sleep_Quality'].map(sleep_mapping)\n",
    "data['Academic_or_Work_Stress'] = data['Academic_or_Work_Stress'].map(stress_mapping)\n",
    "data[\"Previous_Mental_Health_Diagnosis\"] = data[\"Previous_Mental_Health_Diagnosis\"].map(yes_no_dict)\n",
    "data[\"Substance_Use\"] = data[\"Substance_Use\"].map(yes_no_dict)\n",
    "data[\"Recent_Life_Event\"] = data[\"Recent_Life_Event\"].map(yes_no_dict)\n",
    "data[\"Physical_Health_Issues\"] = data[\"Physical_Health_Issues\"].map(yes_no_dict)\n",
    "data[\"Help_Seeking_Behavior\"] = data[\"Help_Seeking_Behavior\"].map(yes_no_dict)\n",
    "data[\"Suicide_Risk\"] = data[\"Suicide_Risk\"].map(yes_no_dict)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad28195a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Person_ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Depression_Score</th>\n",
       "      <th>Anxiety_Score</th>\n",
       "      <th>Stress_Level</th>\n",
       "      <th>Previous_Mental_Health_Diagnosis</th>\n",
       "      <th>Substance_Use</th>\n",
       "      <th>Social_Support_Score</th>\n",
       "      <th>Sleep_Quality</th>\n",
       "      <th>Academic_or_Work_Stress</th>\n",
       "      <th>Recent_Life_Event</th>\n",
       "      <th>Physical_Health_Issues</th>\n",
       "      <th>Self_Esteem_Score</th>\n",
       "      <th>Help_Seeking_Behavior</th>\n",
       "      <th>Suicide_Risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Person_ID</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.010795</td>\n",
       "      <td>-0.009279</td>\n",
       "      <td>0.006240</td>\n",
       "      <td>-0.001815</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>-0.007867</td>\n",
       "      <td>0.020605</td>\n",
       "      <td>-0.000422</td>\n",
       "      <td>-0.009789</td>\n",
       "      <td>0.012397</td>\n",
       "      <td>-0.007506</td>\n",
       "      <td>0.000223</td>\n",
       "      <td>0.001907</td>\n",
       "      <td>-0.009017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>-0.010795</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.008395</td>\n",
       "      <td>-0.000563</td>\n",
       "      <td>-0.004728</td>\n",
       "      <td>-0.008080</td>\n",
       "      <td>0.013614</td>\n",
       "      <td>0.013872</td>\n",
       "      <td>-0.010609</td>\n",
       "      <td>-0.007947</td>\n",
       "      <td>-0.001515</td>\n",
       "      <td>0.009879</td>\n",
       "      <td>-0.010656</td>\n",
       "      <td>0.003948</td>\n",
       "      <td>-0.003302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Depression_Score</th>\n",
       "      <td>-0.009279</td>\n",
       "      <td>0.008395</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.006070</td>\n",
       "      <td>-0.006787</td>\n",
       "      <td>-0.002704</td>\n",
       "      <td>0.005670</td>\n",
       "      <td>-0.010308</td>\n",
       "      <td>-0.002367</td>\n",
       "      <td>-0.015130</td>\n",
       "      <td>0.003529</td>\n",
       "      <td>-0.004847</td>\n",
       "      <td>0.016555</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>0.285124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Anxiety_Score</th>\n",
       "      <td>0.006240</td>\n",
       "      <td>-0.000563</td>\n",
       "      <td>-0.006070</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.012861</td>\n",
       "      <td>0.004557</td>\n",
       "      <td>0.002418</td>\n",
       "      <td>0.004144</td>\n",
       "      <td>0.004113</td>\n",
       "      <td>0.016857</td>\n",
       "      <td>-0.003594</td>\n",
       "      <td>-0.001219</td>\n",
       "      <td>0.002767</td>\n",
       "      <td>-0.001952</td>\n",
       "      <td>0.296989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stress_Level</th>\n",
       "      <td>-0.001815</td>\n",
       "      <td>-0.004728</td>\n",
       "      <td>-0.006787</td>\n",
       "      <td>-0.012861</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.029353</td>\n",
       "      <td>-0.014878</td>\n",
       "      <td>-0.007048</td>\n",
       "      <td>-0.007304</td>\n",
       "      <td>0.007019</td>\n",
       "      <td>0.013314</td>\n",
       "      <td>-0.010457</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>-0.012774</td>\n",
       "      <td>0.287905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Previous_Mental_Health_Diagnosis</th>\n",
       "      <td>0.000044</td>\n",
       "      <td>-0.008080</td>\n",
       "      <td>-0.002704</td>\n",
       "      <td>0.004557</td>\n",
       "      <td>0.029353</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.006520</td>\n",
       "      <td>0.003603</td>\n",
       "      <td>-0.001322</td>\n",
       "      <td>-0.012844</td>\n",
       "      <td>0.004032</td>\n",
       "      <td>0.000161</td>\n",
       "      <td>-0.000632</td>\n",
       "      <td>0.000812</td>\n",
       "      <td>0.014098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Substance_Use</th>\n",
       "      <td>-0.007867</td>\n",
       "      <td>0.013614</td>\n",
       "      <td>0.005670</td>\n",
       "      <td>0.002418</td>\n",
       "      <td>-0.014878</td>\n",
       "      <td>0.006520</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.015955</td>\n",
       "      <td>-0.004990</td>\n",
       "      <td>0.003857</td>\n",
       "      <td>-0.005743</td>\n",
       "      <td>-0.007648</td>\n",
       "      <td>0.001105</td>\n",
       "      <td>0.004804</td>\n",
       "      <td>-0.008439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Social_Support_Score</th>\n",
       "      <td>0.020605</td>\n",
       "      <td>0.013872</td>\n",
       "      <td>-0.010308</td>\n",
       "      <td>0.004144</td>\n",
       "      <td>-0.007048</td>\n",
       "      <td>0.003603</td>\n",
       "      <td>0.015955</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.003338</td>\n",
       "      <td>0.001398</td>\n",
       "      <td>0.004254</td>\n",
       "      <td>-0.004851</td>\n",
       "      <td>0.001343</td>\n",
       "      <td>-0.000442</td>\n",
       "      <td>-0.267730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sleep_Quality</th>\n",
       "      <td>-0.000422</td>\n",
       "      <td>-0.010609</td>\n",
       "      <td>-0.002367</td>\n",
       "      <td>0.004113</td>\n",
       "      <td>-0.007304</td>\n",
       "      <td>-0.001322</td>\n",
       "      <td>-0.004990</td>\n",
       "      <td>0.003338</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.014490</td>\n",
       "      <td>0.012923</td>\n",
       "      <td>0.005141</td>\n",
       "      <td>0.000249</td>\n",
       "      <td>0.004207</td>\n",
       "      <td>0.002538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Academic_or_Work_Stress</th>\n",
       "      <td>-0.009789</td>\n",
       "      <td>-0.007947</td>\n",
       "      <td>-0.015130</td>\n",
       "      <td>0.016857</td>\n",
       "      <td>0.007019</td>\n",
       "      <td>-0.012844</td>\n",
       "      <td>0.003857</td>\n",
       "      <td>0.001398</td>\n",
       "      <td>0.014490</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.003056</td>\n",
       "      <td>0.001543</td>\n",
       "      <td>0.004760</td>\n",
       "      <td>-0.002132</td>\n",
       "      <td>-0.005126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recent_Life_Event</th>\n",
       "      <td>0.012397</td>\n",
       "      <td>-0.001515</td>\n",
       "      <td>0.003529</td>\n",
       "      <td>-0.003594</td>\n",
       "      <td>0.013314</td>\n",
       "      <td>0.004032</td>\n",
       "      <td>-0.005743</td>\n",
       "      <td>0.004254</td>\n",
       "      <td>0.012923</td>\n",
       "      <td>0.003056</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.004563</td>\n",
       "      <td>0.016892</td>\n",
       "      <td>-0.005275</td>\n",
       "      <td>-0.010552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Physical_Health_Issues</th>\n",
       "      <td>-0.007506</td>\n",
       "      <td>0.009879</td>\n",
       "      <td>-0.004847</td>\n",
       "      <td>-0.001219</td>\n",
       "      <td>-0.010457</td>\n",
       "      <td>0.000161</td>\n",
       "      <td>-0.007648</td>\n",
       "      <td>-0.004851</td>\n",
       "      <td>0.005141</td>\n",
       "      <td>0.001543</td>\n",
       "      <td>-0.004563</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.010459</td>\n",
       "      <td>-0.000362</td>\n",
       "      <td>-0.000078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Self_Esteem_Score</th>\n",
       "      <td>0.000223</td>\n",
       "      <td>-0.010656</td>\n",
       "      <td>0.016555</td>\n",
       "      <td>0.002767</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>-0.000632</td>\n",
       "      <td>0.001105</td>\n",
       "      <td>0.001343</td>\n",
       "      <td>0.000249</td>\n",
       "      <td>0.004760</td>\n",
       "      <td>0.016892</td>\n",
       "      <td>0.010459</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000326</td>\n",
       "      <td>-0.259467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Help_Seeking_Behavior</th>\n",
       "      <td>0.001907</td>\n",
       "      <td>0.003948</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>-0.001952</td>\n",
       "      <td>-0.012774</td>\n",
       "      <td>0.000812</td>\n",
       "      <td>0.004804</td>\n",
       "      <td>-0.000442</td>\n",
       "      <td>0.004207</td>\n",
       "      <td>-0.002132</td>\n",
       "      <td>-0.005275</td>\n",
       "      <td>-0.000362</td>\n",
       "      <td>0.000326</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.009010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Suicide_Risk</th>\n",
       "      <td>-0.009017</td>\n",
       "      <td>-0.003302</td>\n",
       "      <td>0.285124</td>\n",
       "      <td>0.296989</td>\n",
       "      <td>0.287905</td>\n",
       "      <td>0.014098</td>\n",
       "      <td>-0.008439</td>\n",
       "      <td>-0.267730</td>\n",
       "      <td>0.002538</td>\n",
       "      <td>-0.005126</td>\n",
       "      <td>-0.010552</td>\n",
       "      <td>-0.000078</td>\n",
       "      <td>-0.259467</td>\n",
       "      <td>-0.009010</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Person_ID       Age  Depression_Score  \\\n",
       "Person_ID                          1.000000 -0.010795         -0.009279   \n",
       "Age                               -0.010795  1.000000          0.008395   \n",
       "Depression_Score                  -0.009279  0.008395          1.000000   \n",
       "Anxiety_Score                      0.006240 -0.000563         -0.006070   \n",
       "Stress_Level                      -0.001815 -0.004728         -0.006787   \n",
       "Previous_Mental_Health_Diagnosis   0.000044 -0.008080         -0.002704   \n",
       "Substance_Use                     -0.007867  0.013614          0.005670   \n",
       "Social_Support_Score               0.020605  0.013872         -0.010308   \n",
       "Sleep_Quality                     -0.000422 -0.010609         -0.002367   \n",
       "Academic_or_Work_Stress           -0.009789 -0.007947         -0.015130   \n",
       "Recent_Life_Event                  0.012397 -0.001515          0.003529   \n",
       "Physical_Health_Issues            -0.007506  0.009879         -0.004847   \n",
       "Self_Esteem_Score                  0.000223 -0.010656          0.016555   \n",
       "Help_Seeking_Behavior              0.001907  0.003948          0.000108   \n",
       "Suicide_Risk                      -0.009017 -0.003302          0.285124   \n",
       "\n",
       "                                  Anxiety_Score  Stress_Level  \\\n",
       "Person_ID                              0.006240     -0.001815   \n",
       "Age                                   -0.000563     -0.004728   \n",
       "Depression_Score                      -0.006070     -0.006787   \n",
       "Anxiety_Score                          1.000000     -0.012861   \n",
       "Stress_Level                          -0.012861      1.000000   \n",
       "Previous_Mental_Health_Diagnosis       0.004557      0.029353   \n",
       "Substance_Use                          0.002418     -0.014878   \n",
       "Social_Support_Score                   0.004144     -0.007048   \n",
       "Sleep_Quality                          0.004113     -0.007304   \n",
       "Academic_or_Work_Stress                0.016857      0.007019   \n",
       "Recent_Life_Event                     -0.003594      0.013314   \n",
       "Physical_Health_Issues                -0.001219     -0.010457   \n",
       "Self_Esteem_Score                      0.002767      0.000050   \n",
       "Help_Seeking_Behavior                 -0.001952     -0.012774   \n",
       "Suicide_Risk                           0.296989      0.287905   \n",
       "\n",
       "                                  Previous_Mental_Health_Diagnosis  \\\n",
       "Person_ID                                                 0.000044   \n",
       "Age                                                      -0.008080   \n",
       "Depression_Score                                         -0.002704   \n",
       "Anxiety_Score                                             0.004557   \n",
       "Stress_Level                                              0.029353   \n",
       "Previous_Mental_Health_Diagnosis                          1.000000   \n",
       "Substance_Use                                             0.006520   \n",
       "Social_Support_Score                                      0.003603   \n",
       "Sleep_Quality                                            -0.001322   \n",
       "Academic_or_Work_Stress                                  -0.012844   \n",
       "Recent_Life_Event                                         0.004032   \n",
       "Physical_Health_Issues                                    0.000161   \n",
       "Self_Esteem_Score                                        -0.000632   \n",
       "Help_Seeking_Behavior                                     0.000812   \n",
       "Suicide_Risk                                              0.014098   \n",
       "\n",
       "                                  Substance_Use  Social_Support_Score  \\\n",
       "Person_ID                             -0.007867              0.020605   \n",
       "Age                                    0.013614              0.013872   \n",
       "Depression_Score                       0.005670             -0.010308   \n",
       "Anxiety_Score                          0.002418              0.004144   \n",
       "Stress_Level                          -0.014878             -0.007048   \n",
       "Previous_Mental_Health_Diagnosis       0.006520              0.003603   \n",
       "Substance_Use                          1.000000              0.015955   \n",
       "Social_Support_Score                   0.015955              1.000000   \n",
       "Sleep_Quality                         -0.004990              0.003338   \n",
       "Academic_or_Work_Stress                0.003857              0.001398   \n",
       "Recent_Life_Event                     -0.005743              0.004254   \n",
       "Physical_Health_Issues                -0.007648             -0.004851   \n",
       "Self_Esteem_Score                      0.001105              0.001343   \n",
       "Help_Seeking_Behavior                  0.004804             -0.000442   \n",
       "Suicide_Risk                          -0.008439             -0.267730   \n",
       "\n",
       "                                  Sleep_Quality  Academic_or_Work_Stress  \\\n",
       "Person_ID                             -0.000422                -0.009789   \n",
       "Age                                   -0.010609                -0.007947   \n",
       "Depression_Score                      -0.002367                -0.015130   \n",
       "Anxiety_Score                          0.004113                 0.016857   \n",
       "Stress_Level                          -0.007304                 0.007019   \n",
       "Previous_Mental_Health_Diagnosis      -0.001322                -0.012844   \n",
       "Substance_Use                         -0.004990                 0.003857   \n",
       "Social_Support_Score                   0.003338                 0.001398   \n",
       "Sleep_Quality                          1.000000                 0.014490   \n",
       "Academic_or_Work_Stress                0.014490                 1.000000   \n",
       "Recent_Life_Event                      0.012923                 0.003056   \n",
       "Physical_Health_Issues                 0.005141                 0.001543   \n",
       "Self_Esteem_Score                      0.000249                 0.004760   \n",
       "Help_Seeking_Behavior                  0.004207                -0.002132   \n",
       "Suicide_Risk                           0.002538                -0.005126   \n",
       "\n",
       "                                  Recent_Life_Event  Physical_Health_Issues  \\\n",
       "Person_ID                                  0.012397               -0.007506   \n",
       "Age                                       -0.001515                0.009879   \n",
       "Depression_Score                           0.003529               -0.004847   \n",
       "Anxiety_Score                             -0.003594               -0.001219   \n",
       "Stress_Level                               0.013314               -0.010457   \n",
       "Previous_Mental_Health_Diagnosis           0.004032                0.000161   \n",
       "Substance_Use                             -0.005743               -0.007648   \n",
       "Social_Support_Score                       0.004254               -0.004851   \n",
       "Sleep_Quality                              0.012923                0.005141   \n",
       "Academic_or_Work_Stress                    0.003056                0.001543   \n",
       "Recent_Life_Event                          1.000000               -0.004563   \n",
       "Physical_Health_Issues                    -0.004563                1.000000   \n",
       "Self_Esteem_Score                          0.016892                0.010459   \n",
       "Help_Seeking_Behavior                     -0.005275               -0.000362   \n",
       "Suicide_Risk                              -0.010552               -0.000078   \n",
       "\n",
       "                                  Self_Esteem_Score  Help_Seeking_Behavior  \\\n",
       "Person_ID                                  0.000223               0.001907   \n",
       "Age                                       -0.010656               0.003948   \n",
       "Depression_Score                           0.016555               0.000108   \n",
       "Anxiety_Score                              0.002767              -0.001952   \n",
       "Stress_Level                               0.000050              -0.012774   \n",
       "Previous_Mental_Health_Diagnosis          -0.000632               0.000812   \n",
       "Substance_Use                              0.001105               0.004804   \n",
       "Social_Support_Score                       0.001343              -0.000442   \n",
       "Sleep_Quality                              0.000249               0.004207   \n",
       "Academic_or_Work_Stress                    0.004760              -0.002132   \n",
       "Recent_Life_Event                          0.016892              -0.005275   \n",
       "Physical_Health_Issues                     0.010459              -0.000362   \n",
       "Self_Esteem_Score                          1.000000               0.000326   \n",
       "Help_Seeking_Behavior                      0.000326               1.000000   \n",
       "Suicide_Risk                              -0.259467              -0.009010   \n",
       "\n",
       "                                  Suicide_Risk  \n",
       "Person_ID                            -0.009017  \n",
       "Age                                  -0.003302  \n",
       "Depression_Score                      0.285124  \n",
       "Anxiety_Score                         0.296989  \n",
       "Stress_Level                          0.287905  \n",
       "Previous_Mental_Health_Diagnosis      0.014098  \n",
       "Substance_Use                        -0.008439  \n",
       "Social_Support_Score                 -0.267730  \n",
       "Sleep_Quality                         0.002538  \n",
       "Academic_or_Work_Stress              -0.005126  \n",
       "Recent_Life_Event                    -0.010552  \n",
       "Physical_Health_Issues               -0.000078  \n",
       "Self_Esteem_Score                    -0.259467  \n",
       "Help_Seeking_Behavior                -0.009010  \n",
       "Suicide_Risk                          1.000000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_matrix = data.corr()\n",
    "corr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "988ddbd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlations with Suicide_Risk:\n",
      "Suicide_Risk                        1.000000\n",
      "Anxiety_Score                       0.296989\n",
      "Stress_Level                        0.287905\n",
      "Depression_Score                    0.285124\n",
      "Previous_Mental_Health_Diagnosis    0.014098\n",
      "Sleep_Quality                       0.002538\n",
      "Physical_Health_Issues             -0.000078\n",
      "Age                                -0.003302\n",
      "Academic_or_Work_Stress            -0.005126\n",
      "Substance_Use                      -0.008439\n",
      "Help_Seeking_Behavior              -0.009010\n",
      "Person_ID                          -0.009017\n",
      "Recent_Life_Event                  -0.010552\n",
      "Self_Esteem_Score                  -0.259467\n",
      "Social_Support_Score               -0.267730\n",
      "Name: Suicide_Risk, dtype: float64\n",
      "\n",
      "Features with low correlation to target (|corr| < 0.1): ['Previous_Mental_Health_Diagnosis', 'Sleep_Quality', 'Physical_Health_Issues', 'Age', 'Academic_or_Work_Stress', 'Substance_Use', 'Help_Seeking_Behavior', 'Person_ID', 'Recent_Life_Event']\n",
      "\n",
      "Highly correlated feature pairs (|corr| > 0.8): []\n",
      "\n",
      "Suggested input features: ['Depression_Score', 'Anxiety_Score', 'Stress_Level', 'Social_Support_Score', 'Self_Esteem_Score']\n"
     ]
    }
   ],
   "source": [
    "# Analyze correlations with the target\n",
    "target_corr = corr_matrix['Suicide_Risk'].sort_values(ascending=False)\n",
    "print(\"Correlations with Suicide_Risk:\")\n",
    "print(target_corr)\n",
    "\n",
    "# Identify features with low correlation to target (e.g., |corr| < 0.1)\n",
    "low_corr_features = target_corr[abs(target_corr) < 0.1].index.tolist()\n",
    "print(f\"\\nFeatures with low correlation to target (|corr| < 0.1): {low_corr_features}\")\n",
    "\n",
    "# Check for high multicollinearity (e.g., |corr| > 0.8 between features, excluding target)\n",
    "features = [col for col in data.columns if col != 'Suicide_Risk' and col != 'Person_ID']\n",
    "feature_corr = corr_matrix.loc[features, features]\n",
    "high_corr_pairs = []\n",
    "for i in range(len(features)):\n",
    "    for j in range(i+1, len(features)):\n",
    "        if abs(feature_corr.iloc[i, j]) > 0.8:\n",
    "            high_corr_pairs.append((features[i], features[j], feature_corr.iloc[i, j]))\n",
    "\n",
    "print(f\"\\nHighly correlated feature pairs (|corr| > 0.8): {high_corr_pairs}\")\n",
    "\n",
    "# Suggested features to keep (exclude Person_ID, low corr, and one from high corr pairs)\n",
    "suggested_features = [col for col in features if col not in low_corr_features]\n",
    "# For high corr pairs, you might remove one (e.g., keep the one with higher corr to target)\n",
    "# Here, simple: keep all except low corr\n",
    "print(f\"\\nSuggested input features: {suggested_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b3c13dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_selected_data = data[suggested_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a2c4ca1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Depression_Score</th>\n",
       "      <th>Anxiety_Score</th>\n",
       "      <th>Stress_Level</th>\n",
       "      <th>Social_Support_Score</th>\n",
       "      <th>Self_Esteem_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Depression_Score  Anxiety_Score  Stress_Level  Social_Support_Score  \\\n",
       "0                    3              9             3                     6   \n",
       "1                    0              1             6                     4   \n",
       "2                    7              2             8                     1   \n",
       "3                    1              4             0                     7   \n",
       "4                    2              2             5                     2   \n",
       "...                ...            ...           ...                   ...   \n",
       "9995                 9              4             6                     8   \n",
       "9996                 2              6             5                     3   \n",
       "9997                 8              0             7                     4   \n",
       "9998                 9              8             6                     7   \n",
       "9999                 3              0             0                     3   \n",
       "\n",
       "      Self_Esteem_Score  \n",
       "0                     7  \n",
       "1                     3  \n",
       "2                     5  \n",
       "3                     6  \n",
       "4                     3  \n",
       "...                 ...  \n",
       "9995                  2  \n",
       "9996                  5  \n",
       "9997                  6  \n",
       "9998                  6  \n",
       "9999                  8  \n",
       "\n",
       "[10000 rows x 5 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_selected_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "15b2ddf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution:\n",
      "Suicide_Risk\n",
      "0    8674\n",
      "1    1326\n",
      "Name: count, dtype: int64\n",
      "Train shape: (8000, 5), Test shape: (2000, 5)\n",
      "Epoch [100/100000], Loss: 2.3971\n",
      "Epoch [200/100000], Loss: 2.2316\n",
      "Epoch [300/100000], Loss: 2.0871\n",
      "Epoch [400/100000], Loss: 1.9632\n",
      "Epoch [500/100000], Loss: 1.8585\n",
      "Epoch [600/100000], Loss: 1.7710\n",
      "Epoch [700/100000], Loss: 1.6979\n",
      "Epoch [800/100000], Loss: 1.6363\n",
      "Epoch [900/100000], Loss: 1.5835\n",
      "Epoch [1000/100000], Loss: 1.5369\n",
      "Epoch [1100/100000], Loss: 1.4948\n",
      "Epoch [1200/100000], Loss: 1.4560\n",
      "Epoch [1300/100000], Loss: 1.4196\n",
      "Epoch [1400/100000], Loss: 1.3852\n",
      "Epoch [1500/100000], Loss: 1.3526\n",
      "Epoch [1600/100000], Loss: 1.3215\n",
      "Epoch [1700/100000], Loss: 1.2917\n",
      "Epoch [1800/100000], Loss: 1.2632\n",
      "Epoch [1900/100000], Loss: 1.2358\n",
      "Epoch [2000/100000], Loss: 1.2095\n",
      "Epoch [2100/100000], Loss: 1.1841\n",
      "Epoch [2200/100000], Loss: 1.1595\n",
      "Epoch [2300/100000], Loss: 1.1358\n",
      "Epoch [2400/100000], Loss: 1.1129\n",
      "Epoch [2500/100000], Loss: 1.0906\n",
      "Epoch [2600/100000], Loss: 1.0690\n",
      "Epoch [2700/100000], Loss: 1.0481\n",
      "Epoch [2800/100000], Loss: 1.0278\n",
      "Epoch [2900/100000], Loss: 1.0081\n",
      "Epoch [3000/100000], Loss: 0.9889\n",
      "Epoch [3100/100000], Loss: 0.9703\n",
      "Epoch [3200/100000], Loss: 0.9522\n",
      "Epoch [3300/100000], Loss: 0.9347\n",
      "Epoch [3400/100000], Loss: 0.9176\n",
      "Epoch [3500/100000], Loss: 0.9010\n",
      "Epoch [3600/100000], Loss: 0.8849\n",
      "Epoch [3700/100000], Loss: 0.8693\n",
      "Epoch [3800/100000], Loss: 0.8540\n",
      "Epoch [3900/100000], Loss: 0.8393\n",
      "Epoch [4000/100000], Loss: 0.8249\n",
      "Epoch [4100/100000], Loss: 0.8109\n",
      "Epoch [4200/100000], Loss: 0.7973\n",
      "Epoch [4300/100000], Loss: 0.7841\n",
      "Epoch [4400/100000], Loss: 0.7713\n",
      "Epoch [4500/100000], Loss: 0.7588\n",
      "Epoch [4600/100000], Loss: 0.7466\n",
      "Epoch [4700/100000], Loss: 0.7348\n",
      "Epoch [4800/100000], Loss: 0.7233\n",
      "Epoch [4900/100000], Loss: 0.7122\n",
      "Epoch [5000/100000], Loss: 0.7013\n",
      "Epoch [5100/100000], Loss: 0.6907\n",
      "Epoch [5200/100000], Loss: 0.6804\n",
      "Epoch [5300/100000], Loss: 0.6704\n",
      "Epoch [5400/100000], Loss: 0.6607\n",
      "Epoch [5500/100000], Loss: 0.6513\n",
      "Epoch [5600/100000], Loss: 0.6421\n",
      "Epoch [5700/100000], Loss: 0.6331\n",
      "Epoch [5800/100000], Loss: 0.6244\n",
      "Epoch [5900/100000], Loss: 0.6159\n",
      "Epoch [6000/100000], Loss: 0.6077\n",
      "Epoch [6100/100000], Loss: 0.5997\n",
      "Epoch [6200/100000], Loss: 0.5919\n",
      "Epoch [6300/100000], Loss: 0.5843\n",
      "Epoch [6400/100000], Loss: 0.5769\n",
      "Epoch [6500/100000], Loss: 0.5697\n",
      "Epoch [6600/100000], Loss: 0.5627\n",
      "Epoch [6700/100000], Loss: 0.5559\n",
      "Epoch [6800/100000], Loss: 0.5493\n",
      "Epoch [6900/100000], Loss: 0.5429\n",
      "Epoch [7000/100000], Loss: 0.5366\n",
      "Epoch [7100/100000], Loss: 0.5306\n",
      "Epoch [7200/100000], Loss: 0.5246\n",
      "Epoch [7300/100000], Loss: 0.5189\n",
      "Epoch [7400/100000], Loss: 0.5133\n",
      "Epoch [7500/100000], Loss: 0.5078\n",
      "Epoch [7600/100000], Loss: 0.5025\n",
      "Epoch [7700/100000], Loss: 0.4974\n",
      "Epoch [7800/100000], Loss: 0.4923\n",
      "Epoch [7900/100000], Loss: 0.4874\n",
      "Epoch [8000/100000], Loss: 0.4827\n",
      "Epoch [8100/100000], Loss: 0.4781\n",
      "Epoch [8200/100000], Loss: 0.4736\n",
      "Epoch [8300/100000], Loss: 0.4692\n",
      "Epoch [8400/100000], Loss: 0.4649\n",
      "Epoch [8500/100000], Loss: 0.4608\n",
      "Epoch [8600/100000], Loss: 0.4568\n",
      "Epoch [8700/100000], Loss: 0.4528\n",
      "Epoch [8800/100000], Loss: 0.4490\n",
      "Epoch [8900/100000], Loss: 0.4453\n",
      "Epoch [9000/100000], Loss: 0.4417\n",
      "Epoch [9100/100000], Loss: 0.4382\n",
      "Epoch [9200/100000], Loss: 0.4348\n",
      "Epoch [9300/100000], Loss: 0.4314\n",
      "Epoch [9400/100000], Loss: 0.4282\n",
      "Epoch [9500/100000], Loss: 0.4251\n",
      "Epoch [9600/100000], Loss: 0.4220\n",
      "Epoch [9700/100000], Loss: 0.4190\n",
      "Epoch [9800/100000], Loss: 0.4161\n",
      "Epoch [9900/100000], Loss: 0.4133\n",
      "Epoch [10000/100000], Loss: 0.4105\n",
      "Epoch [10100/100000], Loss: 0.4078\n",
      "Epoch [10200/100000], Loss: 0.4052\n",
      "Epoch [10300/100000], Loss: 0.4027\n",
      "Epoch [10400/100000], Loss: 0.4002\n",
      "Epoch [10500/100000], Loss: 0.3978\n",
      "Epoch [10600/100000], Loss: 0.3955\n",
      "Epoch [10700/100000], Loss: 0.3932\n",
      "Epoch [10800/100000], Loss: 0.3910\n",
      "Epoch [10900/100000], Loss: 0.3889\n",
      "Epoch [11000/100000], Loss: 0.3868\n",
      "Epoch [11100/100000], Loss: 0.3847\n",
      "Epoch [11200/100000], Loss: 0.3828\n",
      "Epoch [11300/100000], Loss: 0.3808\n",
      "Epoch [11400/100000], Loss: 0.3789\n",
      "Epoch [11500/100000], Loss: 0.3771\n",
      "Epoch [11600/100000], Loss: 0.3753\n",
      "Epoch [11700/100000], Loss: 0.3736\n",
      "Epoch [11800/100000], Loss: 0.3719\n",
      "Epoch [11900/100000], Loss: 0.3703\n",
      "Epoch [12000/100000], Loss: 0.3687\n",
      "Epoch [12100/100000], Loss: 0.3671\n",
      "Epoch [12200/100000], Loss: 0.3656\n",
      "Epoch [12300/100000], Loss: 0.3641\n",
      "Epoch [12400/100000], Loss: 0.3627\n",
      "Epoch [12500/100000], Loss: 0.3613\n",
      "Epoch [12600/100000], Loss: 0.3599\n",
      "Epoch [12700/100000], Loss: 0.3586\n",
      "Epoch [12800/100000], Loss: 0.3573\n",
      "Epoch [12900/100000], Loss: 0.3560\n",
      "Epoch [13000/100000], Loss: 0.3548\n",
      "Epoch [13100/100000], Loss: 0.3536\n",
      "Epoch [13200/100000], Loss: 0.3525\n",
      "Epoch [13300/100000], Loss: 0.3513\n",
      "Epoch [13400/100000], Loss: 0.3502\n",
      "Epoch [13500/100000], Loss: 0.3492\n",
      "Epoch [13600/100000], Loss: 0.3481\n",
      "Epoch [13700/100000], Loss: 0.3471\n",
      "Epoch [13800/100000], Loss: 0.3461\n",
      "Epoch [13900/100000], Loss: 0.3451\n",
      "Epoch [14000/100000], Loss: 0.3442\n",
      "Epoch [14100/100000], Loss: 0.3433\n",
      "Epoch [14200/100000], Loss: 0.3424\n",
      "Epoch [14300/100000], Loss: 0.3415\n",
      "Epoch [14400/100000], Loss: 0.3406\n",
      "Epoch [14500/100000], Loss: 0.3398\n",
      "Epoch [14600/100000], Loss: 0.3390\n",
      "Epoch [14700/100000], Loss: 0.3382\n",
      "Epoch [14800/100000], Loss: 0.3374\n",
      "Epoch [14900/100000], Loss: 0.3367\n",
      "Epoch [15000/100000], Loss: 0.3359\n",
      "Epoch [15100/100000], Loss: 0.3352\n",
      "Epoch [15200/100000], Loss: 0.3345\n",
      "Epoch [15300/100000], Loss: 0.3338\n",
      "Epoch [15400/100000], Loss: 0.3332\n",
      "Epoch [15500/100000], Loss: 0.3325\n",
      "Epoch [15600/100000], Loss: 0.3319\n",
      "Epoch [15700/100000], Loss: 0.3313\n",
      "Epoch [15800/100000], Loss: 0.3307\n",
      "Epoch [15900/100000], Loss: 0.3301\n",
      "Epoch [16000/100000], Loss: 0.3295\n",
      "Epoch [16100/100000], Loss: 0.3289\n",
      "Epoch [16200/100000], Loss: 0.3284\n",
      "Epoch [16300/100000], Loss: 0.3278\n",
      "Epoch [16400/100000], Loss: 0.3273\n",
      "Epoch [16500/100000], Loss: 0.3267\n",
      "Epoch [16600/100000], Loss: 0.3262\n",
      "Epoch [16700/100000], Loss: 0.3257\n",
      "Epoch [16800/100000], Loss: 0.3252\n",
      "Epoch [16900/100000], Loss: 0.3247\n",
      "Epoch [17000/100000], Loss: 0.3242\n",
      "Epoch [17100/100000], Loss: 0.3238\n",
      "Epoch [17200/100000], Loss: 0.3233\n",
      "Epoch [17300/100000], Loss: 0.3228\n",
      "Epoch [17400/100000], Loss: 0.3224\n",
      "Epoch [17500/100000], Loss: 0.3219\n",
      "Epoch [17600/100000], Loss: 0.3215\n",
      "Epoch [17700/100000], Loss: 0.3210\n",
      "Epoch [17800/100000], Loss: 0.3206\n",
      "Epoch [17900/100000], Loss: 0.3202\n",
      "Epoch [18000/100000], Loss: 0.3197\n",
      "Epoch [18100/100000], Loss: 0.3193\n",
      "Epoch [18200/100000], Loss: 0.3189\n",
      "Epoch [18300/100000], Loss: 0.3185\n",
      "Epoch [18400/100000], Loss: 0.3181\n",
      "Epoch [18500/100000], Loss: 0.3177\n",
      "Epoch [18600/100000], Loss: 0.3172\n",
      "Epoch [18700/100000], Loss: 0.3168\n",
      "Epoch [18800/100000], Loss: 0.3164\n",
      "Epoch [18900/100000], Loss: 0.3160\n",
      "Epoch [19000/100000], Loss: 0.3156\n",
      "Epoch [19100/100000], Loss: 0.3152\n",
      "Epoch [19200/100000], Loss: 0.3148\n",
      "Epoch [19300/100000], Loss: 0.3144\n",
      "Epoch [19400/100000], Loss: 0.3140\n",
      "Epoch [19500/100000], Loss: 0.3136\n",
      "Epoch [19600/100000], Loss: 0.3132\n",
      "Epoch [19700/100000], Loss: 0.3128\n",
      "Epoch [19800/100000], Loss: 0.3124\n",
      "Epoch [19900/100000], Loss: 0.3120\n",
      "Epoch [20000/100000], Loss: 0.3116\n",
      "Epoch [20100/100000], Loss: 0.3112\n",
      "Epoch [20200/100000], Loss: 0.3108\n",
      "Epoch [20300/100000], Loss: 0.3104\n",
      "Epoch [20400/100000], Loss: 0.3100\n",
      "Epoch [20500/100000], Loss: 0.3096\n",
      "Epoch [20600/100000], Loss: 0.3092\n",
      "Epoch [20700/100000], Loss: 0.3088\n",
      "Epoch [20800/100000], Loss: 0.3084\n",
      "Epoch [20900/100000], Loss: 0.3080\n",
      "Epoch [21000/100000], Loss: 0.3076\n",
      "Epoch [21100/100000], Loss: 0.3072\n",
      "Epoch [21200/100000], Loss: 0.3069\n",
      "Epoch [21300/100000], Loss: 0.3065\n",
      "Epoch [21400/100000], Loss: 0.3061\n",
      "Epoch [21500/100000], Loss: 0.3057\n",
      "Epoch [21600/100000], Loss: 0.3053\n",
      "Epoch [21700/100000], Loss: 0.3049\n",
      "Epoch [21800/100000], Loss: 0.3045\n",
      "Epoch [21900/100000], Loss: 0.3041\n",
      "Epoch [22000/100000], Loss: 0.3037\n",
      "Epoch [22100/100000], Loss: 0.3034\n",
      "Epoch [22200/100000], Loss: 0.3030\n",
      "Epoch [22300/100000], Loss: 0.3026\n",
      "Epoch [22400/100000], Loss: 0.3022\n",
      "Epoch [22500/100000], Loss: 0.3018\n",
      "Epoch [22600/100000], Loss: 0.3014\n",
      "Epoch [22700/100000], Loss: 0.3011\n",
      "Epoch [22800/100000], Loss: 0.3007\n",
      "Epoch [22900/100000], Loss: 0.3003\n",
      "Epoch [23000/100000], Loss: 0.2999\n",
      "Epoch [23100/100000], Loss: 0.2995\n",
      "Epoch [23200/100000], Loss: 0.2991\n",
      "Epoch [23300/100000], Loss: 0.2988\n",
      "Epoch [23400/100000], Loss: 0.2984\n",
      "Epoch [23500/100000], Loss: 0.2980\n",
      "Epoch [23600/100000], Loss: 0.2976\n",
      "Epoch [23700/100000], Loss: 0.2973\n",
      "Epoch [23800/100000], Loss: 0.2969\n",
      "Epoch [23900/100000], Loss: 0.2965\n",
      "Epoch [24000/100000], Loss: 0.2961\n",
      "Epoch [24100/100000], Loss: 0.2958\n",
      "Epoch [24200/100000], Loss: 0.2954\n",
      "Epoch [24300/100000], Loss: 0.2950\n",
      "Epoch [24400/100000], Loss: 0.2946\n",
      "Epoch [24500/100000], Loss: 0.2943\n",
      "Epoch [24600/100000], Loss: 0.2939\n",
      "Epoch [24700/100000], Loss: 0.2935\n",
      "Epoch [24800/100000], Loss: 0.2932\n",
      "Epoch [24900/100000], Loss: 0.2928\n",
      "Epoch [25000/100000], Loss: 0.2924\n",
      "Epoch [25100/100000], Loss: 0.2920\n",
      "Epoch [25200/100000], Loss: 0.2917\n",
      "Epoch [25300/100000], Loss: 0.2913\n",
      "Epoch [25400/100000], Loss: 0.2909\n",
      "Epoch [25500/100000], Loss: 0.2906\n",
      "Epoch [25600/100000], Loss: 0.2902\n",
      "Epoch [25700/100000], Loss: 0.2898\n",
      "Epoch [25800/100000], Loss: 0.2895\n",
      "Epoch [25900/100000], Loss: 0.2891\n",
      "Epoch [26000/100000], Loss: 0.2887\n",
      "Epoch [26100/100000], Loss: 0.2884\n",
      "Epoch [26200/100000], Loss: 0.2880\n",
      "Epoch [26300/100000], Loss: 0.2877\n",
      "Epoch [26400/100000], Loss: 0.2873\n",
      "Epoch [26500/100000], Loss: 0.2869\n",
      "Epoch [26600/100000], Loss: 0.2866\n",
      "Epoch [26700/100000], Loss: 0.2862\n",
      "Epoch [26800/100000], Loss: 0.2859\n",
      "Epoch [26900/100000], Loss: 0.2855\n",
      "Epoch [27000/100000], Loss: 0.2851\n",
      "Epoch [27100/100000], Loss: 0.2848\n",
      "Epoch [27200/100000], Loss: 0.2844\n",
      "Epoch [27300/100000], Loss: 0.2841\n",
      "Epoch [27400/100000], Loss: 0.2837\n",
      "Epoch [27500/100000], Loss: 0.2834\n",
      "Epoch [27600/100000], Loss: 0.2830\n",
      "Epoch [27700/100000], Loss: 0.2827\n",
      "Epoch [27800/100000], Loss: 0.2823\n",
      "Epoch [27900/100000], Loss: 0.2819\n",
      "Epoch [28000/100000], Loss: 0.2816\n",
      "Epoch [28100/100000], Loss: 0.2812\n",
      "Epoch [28200/100000], Loss: 0.2809\n",
      "Epoch [28300/100000], Loss: 0.2805\n",
      "Epoch [28400/100000], Loss: 0.2802\n",
      "Epoch [28500/100000], Loss: 0.2798\n",
      "Epoch [28600/100000], Loss: 0.2795\n",
      "Epoch [28700/100000], Loss: 0.2791\n",
      "Epoch [28800/100000], Loss: 0.2788\n",
      "Epoch [28900/100000], Loss: 0.2784\n",
      "Epoch [29000/100000], Loss: 0.2781\n",
      "Epoch [29100/100000], Loss: 0.2777\n",
      "Epoch [29200/100000], Loss: 0.2774\n",
      "Epoch [29300/100000], Loss: 0.2771\n",
      "Epoch [29400/100000], Loss: 0.2767\n",
      "Epoch [29500/100000], Loss: 0.2764\n",
      "Epoch [29600/100000], Loss: 0.2760\n",
      "Epoch [29700/100000], Loss: 0.2757\n",
      "Epoch [29800/100000], Loss: 0.2753\n",
      "Epoch [29900/100000], Loss: 0.2750\n",
      "Epoch [30000/100000], Loss: 0.2747\n",
      "Epoch [30100/100000], Loss: 0.2743\n",
      "Epoch [30200/100000], Loss: 0.2740\n",
      "Epoch [30300/100000], Loss: 0.2736\n",
      "Epoch [30400/100000], Loss: 0.2733\n",
      "Epoch [30500/100000], Loss: 0.2730\n",
      "Epoch [30600/100000], Loss: 0.2726\n",
      "Epoch [30700/100000], Loss: 0.2723\n",
      "Epoch [30800/100000], Loss: 0.2719\n",
      "Epoch [30900/100000], Loss: 0.2716\n",
      "Epoch [31000/100000], Loss: 0.2713\n",
      "Epoch [31100/100000], Loss: 0.2709\n",
      "Epoch [31200/100000], Loss: 0.2706\n",
      "Epoch [31300/100000], Loss: 0.2703\n",
      "Epoch [31400/100000], Loss: 0.2699\n",
      "Epoch [31500/100000], Loss: 0.2696\n",
      "Epoch [31600/100000], Loss: 0.2693\n",
      "Epoch [31700/100000], Loss: 0.2689\n",
      "Epoch [31800/100000], Loss: 0.2686\n",
      "Epoch [31900/100000], Loss: 0.2683\n",
      "Epoch [32000/100000], Loss: 0.2679\n",
      "Epoch [32100/100000], Loss: 0.2676\n",
      "Epoch [32200/100000], Loss: 0.2673\n",
      "Epoch [32300/100000], Loss: 0.2669\n",
      "Epoch [32400/100000], Loss: 0.2666\n",
      "Epoch [32500/100000], Loss: 0.2663\n",
      "Epoch [32600/100000], Loss: 0.2660\n",
      "Epoch [32700/100000], Loss: 0.2656\n",
      "Epoch [32800/100000], Loss: 0.2653\n",
      "Epoch [32900/100000], Loss: 0.2650\n",
      "Epoch [33000/100000], Loss: 0.2647\n",
      "Epoch [33100/100000], Loss: 0.2643\n",
      "Epoch [33200/100000], Loss: 0.2640\n",
      "Epoch [33300/100000], Loss: 0.2637\n",
      "Epoch [33400/100000], Loss: 0.2634\n",
      "Epoch [33500/100000], Loss: 0.2630\n",
      "Epoch [33600/100000], Loss: 0.2627\n",
      "Epoch [33700/100000], Loss: 0.2624\n",
      "Epoch [33800/100000], Loss: 0.2621\n",
      "Epoch [33900/100000], Loss: 0.2617\n",
      "Epoch [34000/100000], Loss: 0.2614\n",
      "Epoch [34100/100000], Loss: 0.2611\n",
      "Epoch [34200/100000], Loss: 0.2608\n",
      "Epoch [34300/100000], Loss: 0.2605\n",
      "Epoch [34400/100000], Loss: 0.2601\n",
      "Epoch [34500/100000], Loss: 0.2598\n",
      "Epoch [34600/100000], Loss: 0.2595\n",
      "Epoch [34700/100000], Loss: 0.2592\n",
      "Epoch [34800/100000], Loss: 0.2589\n",
      "Epoch [34900/100000], Loss: 0.2586\n",
      "Epoch [35000/100000], Loss: 0.2582\n",
      "Epoch [35100/100000], Loss: 0.2579\n",
      "Epoch [35200/100000], Loss: 0.2576\n",
      "Epoch [35300/100000], Loss: 0.2573\n",
      "Epoch [35400/100000], Loss: 0.2570\n",
      "Epoch [35500/100000], Loss: 0.2567\n",
      "Epoch [35600/100000], Loss: 0.2564\n",
      "Epoch [35700/100000], Loss: 0.2560\n",
      "Epoch [35800/100000], Loss: 0.2557\n",
      "Epoch [35900/100000], Loss: 0.2554\n",
      "Epoch [36000/100000], Loss: 0.2551\n",
      "Epoch [36100/100000], Loss: 0.2548\n",
      "Epoch [36200/100000], Loss: 0.2545\n",
      "Epoch [36300/100000], Loss: 0.2542\n",
      "Epoch [36400/100000], Loss: 0.2539\n",
      "Epoch [36500/100000], Loss: 0.2536\n",
      "Epoch [36600/100000], Loss: 0.2533\n",
      "Epoch [36700/100000], Loss: 0.2530\n",
      "Epoch [36800/100000], Loss: 0.2527\n",
      "Epoch [36900/100000], Loss: 0.2523\n",
      "Epoch [37000/100000], Loss: 0.2520\n",
      "Epoch [37100/100000], Loss: 0.2517\n",
      "Epoch [37200/100000], Loss: 0.2514\n",
      "Epoch [37300/100000], Loss: 0.2511\n",
      "Epoch [37400/100000], Loss: 0.2508\n",
      "Epoch [37500/100000], Loss: 0.2505\n",
      "Epoch [37600/100000], Loss: 0.2502\n",
      "Epoch [37700/100000], Loss: 0.2499\n",
      "Epoch [37800/100000], Loss: 0.2496\n",
      "Epoch [37900/100000], Loss: 0.2493\n",
      "Epoch [38000/100000], Loss: 0.2490\n",
      "Epoch [38100/100000], Loss: 0.2487\n",
      "Epoch [38200/100000], Loss: 0.2484\n",
      "Epoch [38300/100000], Loss: 0.2481\n",
      "Epoch [38400/100000], Loss: 0.2478\n",
      "Epoch [38500/100000], Loss: 0.2475\n",
      "Epoch [38600/100000], Loss: 0.2472\n",
      "Epoch [38700/100000], Loss: 0.2469\n",
      "Epoch [38800/100000], Loss: 0.2466\n",
      "Epoch [38900/100000], Loss: 0.2463\n",
      "Epoch [39000/100000], Loss: 0.2460\n",
      "Epoch [39100/100000], Loss: 0.2457\n",
      "Epoch [39200/100000], Loss: 0.2454\n",
      "Epoch [39300/100000], Loss: 0.2451\n",
      "Epoch [39400/100000], Loss: 0.2449\n",
      "Epoch [39500/100000], Loss: 0.2446\n",
      "Epoch [39600/100000], Loss: 0.2443\n",
      "Epoch [39700/100000], Loss: 0.2440\n",
      "Epoch [39800/100000], Loss: 0.2437\n",
      "Epoch [39900/100000], Loss: 0.2434\n",
      "Epoch [40000/100000], Loss: 0.2431\n",
      "Epoch [40100/100000], Loss: 0.2428\n",
      "Epoch [40200/100000], Loss: 0.2425\n",
      "Epoch [40300/100000], Loss: 0.2422\n",
      "Epoch [40400/100000], Loss: 0.2419\n",
      "Epoch [40500/100000], Loss: 0.2417\n",
      "Epoch [40600/100000], Loss: 0.2414\n",
      "Epoch [40700/100000], Loss: 0.2411\n",
      "Epoch [40800/100000], Loss: 0.2408\n",
      "Epoch [40900/100000], Loss: 0.2405\n",
      "Epoch [41000/100000], Loss: 0.2402\n",
      "Epoch [41100/100000], Loss: 0.2399\n",
      "Epoch [41200/100000], Loss: 0.2396\n",
      "Epoch [41300/100000], Loss: 0.2394\n",
      "Epoch [41400/100000], Loss: 0.2391\n",
      "Epoch [41500/100000], Loss: 0.2388\n",
      "Epoch [41600/100000], Loss: 0.2385\n",
      "Epoch [41700/100000], Loss: 0.2382\n",
      "Epoch [41800/100000], Loss: 0.2379\n",
      "Epoch [41900/100000], Loss: 0.2377\n",
      "Epoch [42000/100000], Loss: 0.2374\n",
      "Epoch [42100/100000], Loss: 0.2371\n",
      "Epoch [42200/100000], Loss: 0.2368\n",
      "Epoch [42300/100000], Loss: 0.2365\n",
      "Epoch [42400/100000], Loss: 0.2363\n",
      "Epoch [42500/100000], Loss: 0.2360\n",
      "Epoch [42600/100000], Loss: 0.2357\n",
      "Epoch [42700/100000], Loss: 0.2354\n",
      "Epoch [42800/100000], Loss: 0.2351\n",
      "Epoch [42900/100000], Loss: 0.2349\n",
      "Epoch [43000/100000], Loss: 0.2346\n",
      "Epoch [43100/100000], Loss: 0.2343\n",
      "Epoch [43200/100000], Loss: 0.2340\n",
      "Epoch [43300/100000], Loss: 0.2338\n",
      "Epoch [43400/100000], Loss: 0.2335\n",
      "Epoch [43500/100000], Loss: 0.2332\n",
      "Epoch [43600/100000], Loss: 0.2329\n",
      "Epoch [43700/100000], Loss: 0.2327\n",
      "Epoch [43800/100000], Loss: 0.2324\n",
      "Epoch [43900/100000], Loss: 0.2321\n",
      "Epoch [44000/100000], Loss: 0.2318\n",
      "Epoch [44100/100000], Loss: 0.2316\n",
      "Epoch [44200/100000], Loss: 0.2313\n",
      "Epoch [44300/100000], Loss: 0.2310\n",
      "Epoch [44400/100000], Loss: 0.2308\n",
      "Epoch [44500/100000], Loss: 0.2305\n",
      "Epoch [44600/100000], Loss: 0.2302\n",
      "Epoch [44700/100000], Loss: 0.2299\n",
      "Epoch [44800/100000], Loss: 0.2297\n",
      "Epoch [44900/100000], Loss: 0.2294\n",
      "Epoch [45000/100000], Loss: 0.2291\n",
      "Epoch [45100/100000], Loss: 0.2289\n",
      "Epoch [45200/100000], Loss: 0.2286\n",
      "Epoch [45300/100000], Loss: 0.2283\n",
      "Epoch [45400/100000], Loss: 0.2281\n",
      "Epoch [45500/100000], Loss: 0.2278\n",
      "Epoch [45600/100000], Loss: 0.2275\n",
      "Epoch [45700/100000], Loss: 0.2273\n",
      "Epoch [45800/100000], Loss: 0.2270\n",
      "Epoch [45900/100000], Loss: 0.2267\n",
      "Epoch [46000/100000], Loss: 0.2265\n",
      "Epoch [46100/100000], Loss: 0.2262\n",
      "Epoch [46200/100000], Loss: 0.2260\n",
      "Epoch [46300/100000], Loss: 0.2257\n",
      "Epoch [46400/100000], Loss: 0.2254\n",
      "Epoch [46500/100000], Loss: 0.2252\n",
      "Epoch [46600/100000], Loss: 0.2249\n",
      "Epoch [46700/100000], Loss: 0.2247\n",
      "Epoch [46800/100000], Loss: 0.2244\n",
      "Epoch [46900/100000], Loss: 0.2241\n",
      "Epoch [47000/100000], Loss: 0.2239\n",
      "Epoch [47100/100000], Loss: 0.2236\n",
      "Epoch [47200/100000], Loss: 0.2234\n",
      "Epoch [47300/100000], Loss: 0.2231\n",
      "Epoch [47400/100000], Loss: 0.2228\n",
      "Epoch [47500/100000], Loss: 0.2226\n",
      "Epoch [47600/100000], Loss: 0.2223\n",
      "Epoch [47700/100000], Loss: 0.2221\n",
      "Epoch [47800/100000], Loss: 0.2218\n",
      "Epoch [47900/100000], Loss: 0.2216\n",
      "Epoch [48000/100000], Loss: 0.2213\n",
      "Epoch [48100/100000], Loss: 0.2210\n",
      "Epoch [48200/100000], Loss: 0.2208\n",
      "Epoch [48300/100000], Loss: 0.2205\n",
      "Epoch [48400/100000], Loss: 0.2203\n",
      "Epoch [48500/100000], Loss: 0.2200\n",
      "Epoch [48600/100000], Loss: 0.2198\n",
      "Epoch [48700/100000], Loss: 0.2195\n",
      "Epoch [48800/100000], Loss: 0.2193\n",
      "Epoch [48900/100000], Loss: 0.2190\n",
      "Epoch [49000/100000], Loss: 0.2188\n",
      "Epoch [49100/100000], Loss: 0.2185\n",
      "Epoch [49200/100000], Loss: 0.2183\n",
      "Epoch [49300/100000], Loss: 0.2180\n",
      "Epoch [49400/100000], Loss: 0.2178\n",
      "Epoch [49500/100000], Loss: 0.2175\n",
      "Epoch [49600/100000], Loss: 0.2173\n",
      "Epoch [49700/100000], Loss: 0.2170\n",
      "Epoch [49800/100000], Loss: 0.2168\n",
      "Epoch [49900/100000], Loss: 0.2165\n",
      "Epoch [50000/100000], Loss: 0.2163\n",
      "Epoch [50100/100000], Loss: 0.2160\n",
      "Epoch [50200/100000], Loss: 0.2158\n",
      "Epoch [50300/100000], Loss: 0.2155\n",
      "Epoch [50400/100000], Loss: 0.2153\n",
      "Epoch [50500/100000], Loss: 0.2151\n",
      "Epoch [50600/100000], Loss: 0.2148\n",
      "Epoch [50700/100000], Loss: 0.2146\n",
      "Epoch [50800/100000], Loss: 0.2143\n",
      "Epoch [50900/100000], Loss: 0.2141\n",
      "Epoch [51000/100000], Loss: 0.2138\n",
      "Epoch [51100/100000], Loss: 0.2136\n",
      "Epoch [51200/100000], Loss: 0.2134\n",
      "Epoch [51300/100000], Loss: 0.2131\n",
      "Epoch [51400/100000], Loss: 0.2129\n",
      "Epoch [51500/100000], Loss: 0.2126\n",
      "Epoch [51600/100000], Loss: 0.2124\n",
      "Epoch [51700/100000], Loss: 0.2122\n",
      "Epoch [51800/100000], Loss: 0.2119\n",
      "Epoch [51900/100000], Loss: 0.2117\n",
      "Epoch [52000/100000], Loss: 0.2114\n",
      "Epoch [52100/100000], Loss: 0.2112\n",
      "Epoch [52200/100000], Loss: 0.2110\n",
      "Epoch [52300/100000], Loss: 0.2107\n",
      "Epoch [52400/100000], Loss: 0.2105\n",
      "Epoch [52500/100000], Loss: 0.2103\n",
      "Epoch [52600/100000], Loss: 0.2100\n",
      "Epoch [52700/100000], Loss: 0.2098\n",
      "Epoch [52800/100000], Loss: 0.2095\n",
      "Epoch [52900/100000], Loss: 0.2093\n",
      "Epoch [53000/100000], Loss: 0.2091\n",
      "Epoch [53100/100000], Loss: 0.2088\n",
      "Epoch [53200/100000], Loss: 0.2086\n",
      "Epoch [53300/100000], Loss: 0.2084\n",
      "Epoch [53400/100000], Loss: 0.2081\n",
      "Epoch [53500/100000], Loss: 0.2079\n",
      "Epoch [53600/100000], Loss: 0.2077\n",
      "Epoch [53700/100000], Loss: 0.2074\n",
      "Epoch [53800/100000], Loss: 0.2072\n",
      "Epoch [53900/100000], Loss: 0.2070\n",
      "Epoch [54000/100000], Loss: 0.2067\n",
      "Epoch [54100/100000], Loss: 0.2065\n",
      "Epoch [54200/100000], Loss: 0.2063\n",
      "Epoch [54300/100000], Loss: 0.2061\n",
      "Epoch [54400/100000], Loss: 0.2058\n",
      "Epoch [54500/100000], Loss: 0.2056\n",
      "Epoch [54600/100000], Loss: 0.2054\n",
      "Epoch [54700/100000], Loss: 0.2051\n",
      "Epoch [54800/100000], Loss: 0.2049\n",
      "Epoch [54900/100000], Loss: 0.2047\n",
      "Epoch [55000/100000], Loss: 0.2045\n",
      "Epoch [55100/100000], Loss: 0.2042\n",
      "Epoch [55200/100000], Loss: 0.2040\n",
      "Epoch [55300/100000], Loss: 0.2038\n",
      "Epoch [55400/100000], Loss: 0.2036\n",
      "Epoch [55500/100000], Loss: 0.2033\n",
      "Epoch [55600/100000], Loss: 0.2031\n",
      "Epoch [55700/100000], Loss: 0.2029\n",
      "Epoch [55800/100000], Loss: 0.2027\n",
      "Epoch [55900/100000], Loss: 0.2024\n",
      "Epoch [56000/100000], Loss: 0.2022\n",
      "Epoch [56100/100000], Loss: 0.2020\n",
      "Epoch [56200/100000], Loss: 0.2018\n",
      "Epoch [56300/100000], Loss: 0.2015\n",
      "Epoch [56400/100000], Loss: 0.2013\n",
      "Epoch [56500/100000], Loss: 0.2011\n",
      "Epoch [56600/100000], Loss: 0.2009\n",
      "Epoch [56700/100000], Loss: 0.2007\n",
      "Epoch [56800/100000], Loss: 0.2004\n",
      "Epoch [56900/100000], Loss: 0.2002\n",
      "Epoch [57000/100000], Loss: 0.2000\n",
      "Epoch [57100/100000], Loss: 0.1998\n",
      "Epoch [57200/100000], Loss: 0.1996\n",
      "Epoch [57300/100000], Loss: 0.1993\n",
      "Epoch [57400/100000], Loss: 0.1991\n",
      "Epoch [57500/100000], Loss: 0.1989\n",
      "Epoch [57600/100000], Loss: 0.1987\n",
      "Epoch [57700/100000], Loss: 0.1985\n",
      "Epoch [57800/100000], Loss: 0.1982\n",
      "Epoch [57900/100000], Loss: 0.1980\n",
      "Epoch [58000/100000], Loss: 0.1978\n",
      "Epoch [58100/100000], Loss: 0.1976\n",
      "Epoch [58200/100000], Loss: 0.1974\n",
      "Epoch [58300/100000], Loss: 0.1972\n",
      "Epoch [58400/100000], Loss: 0.1970\n",
      "Epoch [58500/100000], Loss: 0.1967\n",
      "Epoch [58600/100000], Loss: 0.1965\n",
      "Epoch [58700/100000], Loss: 0.1963\n",
      "Epoch [58800/100000], Loss: 0.1961\n",
      "Epoch [58900/100000], Loss: 0.1959\n",
      "Epoch [59000/100000], Loss: 0.1957\n",
      "Epoch [59100/100000], Loss: 0.1955\n",
      "Epoch [59200/100000], Loss: 0.1952\n",
      "Epoch [59300/100000], Loss: 0.1950\n",
      "Epoch [59400/100000], Loss: 0.1948\n",
      "Epoch [59500/100000], Loss: 0.1946\n",
      "Epoch [59600/100000], Loss: 0.1944\n",
      "Epoch [59700/100000], Loss: 0.1942\n",
      "Epoch [59800/100000], Loss: 0.1940\n",
      "Epoch [59900/100000], Loss: 0.1938\n",
      "Epoch [60000/100000], Loss: 0.1936\n",
      "Epoch [60100/100000], Loss: 0.1933\n",
      "Epoch [60200/100000], Loss: 0.1931\n",
      "Epoch [60300/100000], Loss: 0.1929\n",
      "Epoch [60400/100000], Loss: 0.1927\n",
      "Epoch [60500/100000], Loss: 0.1925\n",
      "Epoch [60600/100000], Loss: 0.1923\n",
      "Epoch [60700/100000], Loss: 0.1921\n",
      "Epoch [60800/100000], Loss: 0.1919\n",
      "Epoch [60900/100000], Loss: 0.1917\n",
      "Epoch [61000/100000], Loss: 0.1915\n",
      "Epoch [61100/100000], Loss: 0.1913\n",
      "Epoch [61200/100000], Loss: 0.1911\n",
      "Epoch [61300/100000], Loss: 0.1909\n",
      "Epoch [61400/100000], Loss: 0.1907\n",
      "Epoch [61500/100000], Loss: 0.1905\n",
      "Epoch [61600/100000], Loss: 0.1902\n",
      "Epoch [61700/100000], Loss: 0.1900\n",
      "Epoch [61800/100000], Loss: 0.1898\n",
      "Epoch [61900/100000], Loss: 0.1896\n",
      "Epoch [62000/100000], Loss: 0.1894\n",
      "Epoch [62100/100000], Loss: 0.1892\n",
      "Epoch [62200/100000], Loss: 0.1890\n",
      "Epoch [62300/100000], Loss: 0.1888\n",
      "Epoch [62400/100000], Loss: 0.1886\n",
      "Epoch [62500/100000], Loss: 0.1884\n",
      "Epoch [62600/100000], Loss: 0.1882\n",
      "Epoch [62700/100000], Loss: 0.1880\n",
      "Epoch [62800/100000], Loss: 0.1878\n",
      "Epoch [62900/100000], Loss: 0.1876\n",
      "Epoch [63000/100000], Loss: 0.1874\n",
      "Epoch [63100/100000], Loss: 0.1872\n",
      "Epoch [63200/100000], Loss: 0.1870\n",
      "Epoch [63300/100000], Loss: 0.1868\n",
      "Epoch [63400/100000], Loss: 0.1866\n",
      "Epoch [63500/100000], Loss: 0.1864\n",
      "Epoch [63600/100000], Loss: 0.1862\n",
      "Epoch [63700/100000], Loss: 0.1860\n",
      "Epoch [63800/100000], Loss: 0.1858\n",
      "Epoch [63900/100000], Loss: 0.1856\n",
      "Epoch [64000/100000], Loss: 0.1854\n",
      "Epoch [64100/100000], Loss: 0.1852\n",
      "Epoch [64200/100000], Loss: 0.1851\n",
      "Epoch [64300/100000], Loss: 0.1849\n",
      "Epoch [64400/100000], Loss: 0.1847\n",
      "Epoch [64500/100000], Loss: 0.1845\n",
      "Epoch [64600/100000], Loss: 0.1843\n",
      "Epoch [64700/100000], Loss: 0.1841\n",
      "Epoch [64800/100000], Loss: 0.1839\n",
      "Epoch [64900/100000], Loss: 0.1837\n",
      "Epoch [65000/100000], Loss: 0.1835\n",
      "Epoch [65100/100000], Loss: 0.1833\n",
      "Epoch [65200/100000], Loss: 0.1831\n",
      "Epoch [65300/100000], Loss: 0.1829\n",
      "Epoch [65400/100000], Loss: 0.1827\n",
      "Epoch [65500/100000], Loss: 0.1825\n",
      "Epoch [65600/100000], Loss: 0.1823\n",
      "Epoch [65700/100000], Loss: 0.1822\n",
      "Epoch [65800/100000], Loss: 0.1820\n",
      "Epoch [65900/100000], Loss: 0.1818\n",
      "Epoch [66000/100000], Loss: 0.1816\n",
      "Epoch [66100/100000], Loss: 0.1814\n",
      "Epoch [66200/100000], Loss: 0.1812\n",
      "Epoch [66300/100000], Loss: 0.1810\n",
      "Epoch [66400/100000], Loss: 0.1808\n",
      "Epoch [66500/100000], Loss: 0.1806\n",
      "Epoch [66600/100000], Loss: 0.1804\n",
      "Epoch [66700/100000], Loss: 0.1803\n",
      "Epoch [66800/100000], Loss: 0.1801\n",
      "Epoch [66900/100000], Loss: 0.1799\n",
      "Epoch [67000/100000], Loss: 0.1797\n",
      "Epoch [67100/100000], Loss: 0.1795\n",
      "Epoch [67200/100000], Loss: 0.1793\n",
      "Epoch [67300/100000], Loss: 0.1791\n",
      "Epoch [67400/100000], Loss: 0.1789\n",
      "Epoch [67500/100000], Loss: 0.1788\n",
      "Epoch [67600/100000], Loss: 0.1786\n",
      "Epoch [67700/100000], Loss: 0.1784\n",
      "Epoch [67800/100000], Loss: 0.1782\n",
      "Epoch [67900/100000], Loss: 0.1780\n",
      "Epoch [68000/100000], Loss: 0.1778\n",
      "Epoch [68100/100000], Loss: 0.1777\n",
      "Epoch [68200/100000], Loss: 0.1775\n",
      "Epoch [68300/100000], Loss: 0.1773\n",
      "Epoch [68400/100000], Loss: 0.1771\n",
      "Epoch [68500/100000], Loss: 0.1769\n",
      "Epoch [68600/100000], Loss: 0.1767\n",
      "Epoch [68700/100000], Loss: 0.1766\n",
      "Epoch [68800/100000], Loss: 0.1764\n",
      "Epoch [68900/100000], Loss: 0.1762\n",
      "Epoch [69000/100000], Loss: 0.1760\n",
      "Epoch [69100/100000], Loss: 0.1758\n",
      "Epoch [69200/100000], Loss: 0.1756\n",
      "Epoch [69300/100000], Loss: 0.1755\n",
      "Epoch [69400/100000], Loss: 0.1753\n",
      "Epoch [69500/100000], Loss: 0.1751\n",
      "Epoch [69600/100000], Loss: 0.1749\n",
      "Epoch [69700/100000], Loss: 0.1747\n",
      "Epoch [69800/100000], Loss: 0.1746\n",
      "Epoch [69900/100000], Loss: 0.1744\n",
      "Epoch [70000/100000], Loss: 0.1742\n",
      "Epoch [70100/100000], Loss: 0.1740\n",
      "Epoch [70200/100000], Loss: 0.1739\n",
      "Epoch [70300/100000], Loss: 0.1737\n",
      "Epoch [70400/100000], Loss: 0.1735\n",
      "Epoch [70500/100000], Loss: 0.1733\n",
      "Epoch [70600/100000], Loss: 0.1731\n",
      "Epoch [70700/100000], Loss: 0.1730\n",
      "Epoch [70800/100000], Loss: 0.1728\n",
      "Epoch [70900/100000], Loss: 0.1726\n",
      "Epoch [71000/100000], Loss: 0.1724\n",
      "Epoch [71100/100000], Loss: 0.1723\n",
      "Epoch [71200/100000], Loss: 0.1721\n",
      "Epoch [71300/100000], Loss: 0.1719\n",
      "Epoch [71400/100000], Loss: 0.1717\n",
      "Epoch [71500/100000], Loss: 0.1716\n",
      "Epoch [71600/100000], Loss: 0.1714\n",
      "Epoch [71700/100000], Loss: 0.1712\n",
      "Epoch [71800/100000], Loss: 0.1710\n",
      "Epoch [71900/100000], Loss: 0.1709\n",
      "Epoch [72000/100000], Loss: 0.1707\n",
      "Epoch [72100/100000], Loss: 0.1705\n",
      "Epoch [72200/100000], Loss: 0.1703\n",
      "Epoch [72300/100000], Loss: 0.1702\n",
      "Epoch [72400/100000], Loss: 0.1700\n",
      "Epoch [72500/100000], Loss: 0.1698\n",
      "Epoch [72600/100000], Loss: 0.1697\n",
      "Epoch [72700/100000], Loss: 0.1695\n",
      "Epoch [72800/100000], Loss: 0.1693\n",
      "Epoch [72900/100000], Loss: 0.1691\n",
      "Epoch [73000/100000], Loss: 0.1690\n",
      "Epoch [73100/100000], Loss: 0.1688\n",
      "Epoch [73200/100000], Loss: 0.1686\n",
      "Epoch [73300/100000], Loss: 0.1685\n",
      "Epoch [73400/100000], Loss: 0.1683\n",
      "Epoch [73500/100000], Loss: 0.1681\n",
      "Epoch [73600/100000], Loss: 0.1680\n",
      "Epoch [73700/100000], Loss: 0.1678\n",
      "Epoch [73800/100000], Loss: 0.1676\n",
      "Epoch [73900/100000], Loss: 0.1675\n",
      "Epoch [74000/100000], Loss: 0.1673\n",
      "Epoch [74100/100000], Loss: 0.1671\n",
      "Epoch [74200/100000], Loss: 0.1669\n",
      "Epoch [74300/100000], Loss: 0.1668\n",
      "Epoch [74400/100000], Loss: 0.1666\n",
      "Epoch [74500/100000], Loss: 0.1664\n",
      "Epoch [74600/100000], Loss: 0.1663\n",
      "Epoch [74700/100000], Loss: 0.1661\n",
      "Epoch [74800/100000], Loss: 0.1660\n",
      "Epoch [74900/100000], Loss: 0.1658\n",
      "Epoch [75000/100000], Loss: 0.1656\n",
      "Epoch [75100/100000], Loss: 0.1655\n",
      "Epoch [75200/100000], Loss: 0.1653\n",
      "Epoch [75300/100000], Loss: 0.1651\n",
      "Epoch [75400/100000], Loss: 0.1650\n",
      "Epoch [75500/100000], Loss: 0.1648\n",
      "Epoch [75600/100000], Loss: 0.1646\n",
      "Epoch [75700/100000], Loss: 0.1645\n",
      "Epoch [75800/100000], Loss: 0.1643\n",
      "Epoch [75900/100000], Loss: 0.1641\n",
      "Epoch [76000/100000], Loss: 0.1640\n",
      "Epoch [76100/100000], Loss: 0.1638\n",
      "Epoch [76200/100000], Loss: 0.1637\n",
      "Epoch [76300/100000], Loss: 0.1635\n",
      "Epoch [76400/100000], Loss: 0.1633\n",
      "Epoch [76500/100000], Loss: 0.1632\n",
      "Epoch [76600/100000], Loss: 0.1630\n",
      "Epoch [76700/100000], Loss: 0.1628\n",
      "Epoch [76800/100000], Loss: 0.1627\n",
      "Epoch [76900/100000], Loss: 0.1625\n",
      "Epoch [77000/100000], Loss: 0.1624\n",
      "Epoch [77100/100000], Loss: 0.1622\n",
      "Epoch [77200/100000], Loss: 0.1620\n",
      "Epoch [77300/100000], Loss: 0.1619\n",
      "Epoch [77400/100000], Loss: 0.1617\n",
      "Epoch [77500/100000], Loss: 0.1616\n",
      "Epoch [77600/100000], Loss: 0.1614\n",
      "Epoch [77700/100000], Loss: 0.1613\n",
      "Epoch [77800/100000], Loss: 0.1611\n",
      "Epoch [77900/100000], Loss: 0.1609\n",
      "Epoch [78000/100000], Loss: 0.1608\n",
      "Epoch [78100/100000], Loss: 0.1606\n",
      "Epoch [78200/100000], Loss: 0.1605\n",
      "Epoch [78300/100000], Loss: 0.1603\n",
      "Epoch [78400/100000], Loss: 0.1601\n",
      "Epoch [78500/100000], Loss: 0.1600\n",
      "Epoch [78600/100000], Loss: 0.1598\n",
      "Epoch [78700/100000], Loss: 0.1597\n",
      "Epoch [78800/100000], Loss: 0.1595\n",
      "Epoch [78900/100000], Loss: 0.1594\n",
      "Epoch [79000/100000], Loss: 0.1592\n",
      "Epoch [79100/100000], Loss: 0.1590\n",
      "Epoch [79200/100000], Loss: 0.1589\n",
      "Epoch [79300/100000], Loss: 0.1587\n",
      "Epoch [79400/100000], Loss: 0.1586\n",
      "Epoch [79500/100000], Loss: 0.1584\n",
      "Epoch [79600/100000], Loss: 0.1583\n",
      "Epoch [79700/100000], Loss: 0.1581\n",
      "Epoch [79800/100000], Loss: 0.1580\n",
      "Epoch [79900/100000], Loss: 0.1578\n",
      "Epoch [80000/100000], Loss: 0.1577\n",
      "Epoch [80100/100000], Loss: 0.1575\n",
      "Epoch [80200/100000], Loss: 0.1573\n",
      "Epoch [80300/100000], Loss: 0.1572\n",
      "Epoch [80400/100000], Loss: 0.1570\n",
      "Epoch [80500/100000], Loss: 0.1569\n",
      "Epoch [80600/100000], Loss: 0.1567\n",
      "Epoch [80700/100000], Loss: 0.1566\n",
      "Epoch [80800/100000], Loss: 0.1564\n",
      "Epoch [80900/100000], Loss: 0.1563\n",
      "Epoch [81000/100000], Loss: 0.1561\n",
      "Epoch [81100/100000], Loss: 0.1560\n",
      "Epoch [81200/100000], Loss: 0.1558\n",
      "Epoch [81300/100000], Loss: 0.1557\n",
      "Epoch [81400/100000], Loss: 0.1555\n",
      "Epoch [81500/100000], Loss: 0.1554\n",
      "Epoch [81600/100000], Loss: 0.1552\n",
      "Epoch [81700/100000], Loss: 0.1551\n",
      "Epoch [81800/100000], Loss: 0.1549\n",
      "Epoch [81900/100000], Loss: 0.1548\n",
      "Epoch [82000/100000], Loss: 0.1546\n",
      "Epoch [82100/100000], Loss: 0.1545\n",
      "Epoch [82200/100000], Loss: 0.1543\n",
      "Epoch [82300/100000], Loss: 0.1542\n",
      "Epoch [82400/100000], Loss: 0.1540\n",
      "Epoch [82500/100000], Loss: 0.1539\n",
      "Epoch [82600/100000], Loss: 0.1537\n",
      "Epoch [82700/100000], Loss: 0.1536\n",
      "Epoch [82800/100000], Loss: 0.1534\n",
      "Epoch [82900/100000], Loss: 0.1533\n",
      "Epoch [83000/100000], Loss: 0.1531\n",
      "Epoch [83100/100000], Loss: 0.1530\n",
      "Epoch [83200/100000], Loss: 0.1529\n",
      "Epoch [83300/100000], Loss: 0.1527\n",
      "Epoch [83400/100000], Loss: 0.1526\n",
      "Epoch [83500/100000], Loss: 0.1524\n",
      "Epoch [83600/100000], Loss: 0.1523\n",
      "Epoch [83700/100000], Loss: 0.1521\n",
      "Epoch [83800/100000], Loss: 0.1520\n",
      "Epoch [83900/100000], Loss: 0.1518\n",
      "Epoch [84000/100000], Loss: 0.1517\n",
      "Epoch [84100/100000], Loss: 0.1515\n",
      "Epoch [84200/100000], Loss: 0.1514\n",
      "Epoch [84300/100000], Loss: 0.1513\n",
      "Epoch [84400/100000], Loss: 0.1511\n",
      "Epoch [84500/100000], Loss: 0.1510\n",
      "Epoch [84600/100000], Loss: 0.1508\n",
      "Epoch [84700/100000], Loss: 0.1507\n",
      "Epoch [84800/100000], Loss: 0.1505\n",
      "Epoch [84900/100000], Loss: 0.1504\n",
      "Epoch [85000/100000], Loss: 0.1502\n",
      "Epoch [85100/100000], Loss: 0.1501\n",
      "Epoch [85200/100000], Loss: 0.1500\n",
      "Epoch [85300/100000], Loss: 0.1498\n",
      "Epoch [85400/100000], Loss: 0.1497\n",
      "Epoch [85500/100000], Loss: 0.1495\n",
      "Epoch [85600/100000], Loss: 0.1494\n",
      "Epoch [85700/100000], Loss: 0.1493\n",
      "Epoch [85800/100000], Loss: 0.1491\n",
      "Epoch [85900/100000], Loss: 0.1490\n",
      "Epoch [86000/100000], Loss: 0.1488\n",
      "Epoch [86100/100000], Loss: 0.1487\n",
      "Epoch [86200/100000], Loss: 0.1486\n",
      "Epoch [86300/100000], Loss: 0.1484\n",
      "Epoch [86400/100000], Loss: 0.1483\n",
      "Epoch [86500/100000], Loss: 0.1481\n",
      "Epoch [86600/100000], Loss: 0.1480\n",
      "Epoch [86700/100000], Loss: 0.1479\n",
      "Epoch [86800/100000], Loss: 0.1477\n",
      "Epoch [86900/100000], Loss: 0.1476\n",
      "Epoch [87000/100000], Loss: 0.1474\n",
      "Epoch [87100/100000], Loss: 0.1473\n",
      "Epoch [87200/100000], Loss: 0.1472\n",
      "Epoch [87300/100000], Loss: 0.1470\n",
      "Epoch [87400/100000], Loss: 0.1469\n",
      "Epoch [87500/100000], Loss: 0.1468\n",
      "Epoch [87600/100000], Loss: 0.1466\n",
      "Epoch [87700/100000], Loss: 0.1465\n",
      "Epoch [87800/100000], Loss: 0.1463\n",
      "Epoch [87900/100000], Loss: 0.1462\n",
      "Epoch [88000/100000], Loss: 0.1461\n",
      "Epoch [88100/100000], Loss: 0.1459\n",
      "Epoch [88200/100000], Loss: 0.1458\n",
      "Epoch [88300/100000], Loss: 0.1457\n",
      "Epoch [88400/100000], Loss: 0.1455\n",
      "Epoch [88500/100000], Loss: 0.1454\n",
      "Epoch [88600/100000], Loss: 0.1453\n",
      "Epoch [88700/100000], Loss: 0.1451\n",
      "Epoch [88800/100000], Loss: 0.1450\n",
      "Epoch [88900/100000], Loss: 0.1448\n",
      "Epoch [89000/100000], Loss: 0.1447\n",
      "Epoch [89100/100000], Loss: 0.1446\n",
      "Epoch [89200/100000], Loss: 0.1444\n",
      "Epoch [89300/100000], Loss: 0.1443\n",
      "Epoch [89400/100000], Loss: 0.1442\n",
      "Epoch [89500/100000], Loss: 0.1440\n",
      "Epoch [89600/100000], Loss: 0.1439\n",
      "Epoch [89700/100000], Loss: 0.1438\n",
      "Epoch [89800/100000], Loss: 0.1436\n",
      "Epoch [89900/100000], Loss: 0.1435\n",
      "Epoch [90000/100000], Loss: 0.1434\n",
      "Epoch [90100/100000], Loss: 0.1432\n",
      "Epoch [90200/100000], Loss: 0.1431\n",
      "Epoch [90300/100000], Loss: 0.1430\n",
      "Epoch [90400/100000], Loss: 0.1429\n",
      "Epoch [90500/100000], Loss: 0.1427\n",
      "Epoch [90600/100000], Loss: 0.1426\n",
      "Epoch [90700/100000], Loss: 0.1425\n",
      "Epoch [90800/100000], Loss: 0.1423\n",
      "Epoch [90900/100000], Loss: 0.1422\n",
      "Epoch [91000/100000], Loss: 0.1421\n",
      "Epoch [91100/100000], Loss: 0.1419\n",
      "Epoch [91200/100000], Loss: 0.1418\n",
      "Epoch [91300/100000], Loss: 0.1417\n",
      "Epoch [91400/100000], Loss: 0.1416\n",
      "Epoch [91500/100000], Loss: 0.1414\n",
      "Epoch [91600/100000], Loss: 0.1413\n",
      "Epoch [91700/100000], Loss: 0.1412\n",
      "Epoch [91800/100000], Loss: 0.1410\n",
      "Epoch [91900/100000], Loss: 0.1409\n",
      "Epoch [92000/100000], Loss: 0.1408\n",
      "Epoch [92100/100000], Loss: 0.1407\n",
      "Epoch [92200/100000], Loss: 0.1405\n",
      "Epoch [92300/100000], Loss: 0.1404\n",
      "Epoch [92400/100000], Loss: 0.1403\n",
      "Epoch [92500/100000], Loss: 0.1401\n",
      "Epoch [92600/100000], Loss: 0.1400\n",
      "Epoch [92700/100000], Loss: 0.1399\n",
      "Epoch [92800/100000], Loss: 0.1398\n",
      "Epoch [92900/100000], Loss: 0.1396\n",
      "Epoch [93000/100000], Loss: 0.1395\n",
      "Epoch [93100/100000], Loss: 0.1394\n",
      "Epoch [93200/100000], Loss: 0.1393\n",
      "Epoch [93300/100000], Loss: 0.1391\n",
      "Epoch [93400/100000], Loss: 0.1390\n",
      "Epoch [93500/100000], Loss: 0.1389\n",
      "Epoch [93600/100000], Loss: 0.1388\n",
      "Epoch [93700/100000], Loss: 0.1386\n",
      "Epoch [93800/100000], Loss: 0.1385\n",
      "Epoch [93900/100000], Loss: 0.1384\n",
      "Epoch [94000/100000], Loss: 0.1383\n",
      "Epoch [94100/100000], Loss: 0.1381\n",
      "Epoch [94200/100000], Loss: 0.1380\n",
      "Epoch [94300/100000], Loss: 0.1379\n",
      "Epoch [94400/100000], Loss: 0.1378\n",
      "Epoch [94500/100000], Loss: 0.1376\n",
      "Epoch [94600/100000], Loss: 0.1375\n",
      "Epoch [94700/100000], Loss: 0.1374\n",
      "Epoch [94800/100000], Loss: 0.1373\n",
      "Epoch [94900/100000], Loss: 0.1371\n",
      "Epoch [95000/100000], Loss: 0.1370\n",
      "Epoch [95100/100000], Loss: 0.1369\n",
      "Epoch [95200/100000], Loss: 0.1368\n",
      "Epoch [95300/100000], Loss: 0.1367\n",
      "Epoch [95400/100000], Loss: 0.1365\n",
      "Epoch [95500/100000], Loss: 0.1364\n",
      "Epoch [95600/100000], Loss: 0.1363\n",
      "Epoch [95700/100000], Loss: 0.1362\n",
      "Epoch [95800/100000], Loss: 0.1360\n",
      "Epoch [95900/100000], Loss: 0.1359\n",
      "Epoch [96000/100000], Loss: 0.1358\n",
      "Epoch [96100/100000], Loss: 0.1357\n",
      "Epoch [96200/100000], Loss: 0.1356\n",
      "Epoch [96300/100000], Loss: 0.1354\n",
      "Epoch [96400/100000], Loss: 0.1353\n",
      "Epoch [96500/100000], Loss: 0.1352\n",
      "Epoch [96600/100000], Loss: 0.1351\n",
      "Epoch [96700/100000], Loss: 0.1350\n",
      "Epoch [96800/100000], Loss: 0.1348\n",
      "Epoch [96900/100000], Loss: 0.1347\n",
      "Epoch [97000/100000], Loss: 0.1346\n",
      "Epoch [97100/100000], Loss: 0.1345\n",
      "Epoch [97200/100000], Loss: 0.1344\n",
      "Epoch [97300/100000], Loss: 0.1342\n",
      "Epoch [97400/100000], Loss: 0.1341\n",
      "Epoch [97500/100000], Loss: 0.1340\n",
      "Epoch [97600/100000], Loss: 0.1339\n",
      "Epoch [97700/100000], Loss: 0.1338\n",
      "Epoch [97800/100000], Loss: 0.1337\n",
      "Epoch [97900/100000], Loss: 0.1335\n",
      "Epoch [98000/100000], Loss: 0.1334\n",
      "Epoch [98100/100000], Loss: 0.1333\n",
      "Epoch [98200/100000], Loss: 0.1332\n",
      "Epoch [98300/100000], Loss: 0.1331\n",
      "Epoch [98400/100000], Loss: 0.1330\n",
      "Epoch [98500/100000], Loss: 0.1328\n",
      "Epoch [98600/100000], Loss: 0.1327\n",
      "Epoch [98700/100000], Loss: 0.1326\n",
      "Epoch [98800/100000], Loss: 0.1325\n",
      "Epoch [98900/100000], Loss: 0.1324\n",
      "Epoch [99000/100000], Loss: 0.1323\n",
      "Epoch [99100/100000], Loss: 0.1321\n",
      "Epoch [99200/100000], Loss: 0.1320\n",
      "Epoch [99300/100000], Loss: 0.1319\n",
      "Epoch [99400/100000], Loss: 0.1318\n",
      "Epoch [99500/100000], Loss: 0.1317\n",
      "Epoch [99600/100000], Loss: 0.1316\n",
      "Epoch [99700/100000], Loss: 0.1314\n",
      "Epoch [99800/100000], Loss: 0.1313\n",
      "Epoch [99900/100000], Loss: 0.1312\n",
      "Epoch [100000/100000], Loss: 0.1311\n",
      "Sample probabilities for test set:\n",
      "[9.9999988e-01 4.0034978e-03 2.0299505e-01 3.1022340e-04 8.6840248e-01\n",
      " 3.7566415e-04 9.9396634e-01 6.1072533e-05 3.7412037e-04 1.2235401e-05]\n",
      "Accuracy: 0.955\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.97      1735\n",
      "           1       0.75      1.00      0.85       265\n",
      "\n",
      "    accuracy                           0.95      2000\n",
      "   macro avg       0.87      0.97      0.91      2000\n",
      "weighted avg       0.97      0.95      0.96      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Prepare features and target\n",
    "X = feature_selected_data\n",
    "y = data['Suicide_Risk']\n",
    "\n",
    "# Check class balance\n",
    "print(\"Class distribution:\")\n",
    "print(y.value_counts())\n",
    "\n",
    "# Split into train and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(f\"Train shape: {X_train.shape}, Test shape: {X_test.shape}\")\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).unsqueeze(1)\n",
    "X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "# Define Logistic Regression model in PyTorch\n",
    "class LogisticRegressionModel(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(LogisticRegressionModel, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "model = LogisticRegressionModel(X_train.shape[1])\n",
    "\n",
    "# Handle class imbalance with pos_weight\n",
    "pos_weight = torch.tensor([len(y_train) / sum(y_train)])  # Weight for positive class\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)  # Lower lr for stability\n",
    "\n",
    "# Train the model (more epochs)\n",
    "num_epochs = 100000\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X_train_tensor)\n",
    "    loss = criterion(outputs, y_train_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if (epoch+1) % 100 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Get probabilities on test set (apply sigmoid to logits)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    logits = model(X_test_tensor)\n",
    "    probabilities = torch.sigmoid(logits).squeeze().numpy()\n",
    "print(\"Sample probabilities for test set:\")\n",
    "print(probabilities[:10])  # First 10\n",
    "\n",
    "# Predictions (threshold at 0.5)\n",
    "predictions = (probabilities > 0.5).astype(int)\n",
    "\n",
    "# Evaluate\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "print(f\"Accuracy: {accuracy_score(y_test, predictions)}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e0ad3e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After training, in the model cell\n",
    "torch.save(model.state_dict(), 'suicide_risk_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bda028",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
